{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-06T17:47:01.512199Z",
     "iopub.status.busy": "2024-11-06T17:47:01.51148Z",
     "iopub.status.idle": "2024-11-06T17:47:01.870349Z",
     "shell.execute_reply": "2024-11-06T17:47:01.869419Z",
     "shell.execute_reply.started": "2024-11-06T17:47:01.512157Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Эта среда Python 3 поставляется со множеством полезных аналитических библиотек.\n",
    "# Она определяется образом Docker kaggle/python: https://github.com/kaggle/docker-python\n",
    "# Например, вот несколько полезных пакетов для загрузки.\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача:\n",
    "**предсказать жанр фильма по описанию к нему.**\n",
    "\n",
    "В нашем распоряжении два датасета: тренировочный с 54214 фильмами и тестовый 54200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:47:05.004036Z",
     "iopub.status.busy": "2024-11-06T17:47:05.003511Z",
     "iopub.status.idle": "2024-11-06T17:47:08.031861Z",
     "shell.execute_reply": "2024-11-06T17:47:08.030732Z",
     "shell.execute_reply.started": "2024-11-06T17:47:05.003996Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# импортируем необходимые пакеты\n",
    "import pandas as pd                 # для работы с табличными данными\n",
    "import matplotlib.pyplot as plt     # для визуализации\n",
    "import seaborn as sns               # для визуализации\n",
    "\n",
    "import nltk                         # библиотека для обработки естественного языка\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# загрузка в текущую директорию пакета wordnet\n",
    "!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/\n",
    "\n",
    "import string\n",
    "import re                           # библиотека обработки регулярных выражений\n",
    "\n",
    "from sklearn.model_selection import train_test_split         # инструмент сплитования набора данных\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # векторизация текста\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression          # алгоритм логистической регрессии\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay # набор метрик для задач классификации\n",
    "\n",
    "from catboost import Pool, CatBoostClassifier               # библиотека градиентного спуска\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:47:09.157463Z",
     "iopub.status.busy": "2024-11-06T17:47:09.156727Z",
     "iopub.status.idle": "2024-11-06T17:47:09.998554Z",
     "shell.execute_reply": "2024-11-06T17:47:09.997304Z",
     "shell.execute_reply.started": "2024-11-06T17:47:09.157399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# загружаем тренировочный набор данных\n",
    "train_data = pd.read_csv('/kaggle/input/sf-dl-movie-genre-classification/train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:47:19.59652Z",
     "iopub.status.busy": "2024-11-06T17:47:19.595803Z",
     "iopub.status.idle": "2024-11-06T17:47:20.366609Z",
     "shell.execute_reply": "2024-11-06T17:47:20.365664Z",
     "shell.execute_reply.started": "2024-11-06T17:47:19.596479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# загружаем тестовый набор данных\n",
    "test_data = pd.read_csv('/kaggle/input/sf-dl-movie-genre-classification/test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Общая информация\n",
    "Посмотрим, все ли фильмы содержат категорию-жанр и текстовое описание или имеются пропуски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T14:42:06.024679Z",
     "iopub.status.busy": "2024-11-06T14:42:06.023882Z",
     "iopub.status.idle": "2024-11-06T14:42:06.082097Z",
     "shell.execute_reply": "2024-11-06T14:42:06.081104Z",
     "shell.execute_reply.started": "2024-11-06T14:42:06.024639Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "display(train_data.info())\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков нет, но как распределены фильмы по жанрам?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T14:43:41.182101Z",
     "iopub.status.busy": "2024-11-06T14:43:41.18119Z",
     "iopub.status.idle": "2024-11-06T14:43:41.822744Z",
     "shell.execute_reply": "2024-11-06T14:43:41.821796Z",
     "shell.execute_reply.started": "2024-11-06T14:43:41.182055Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "sns.countplot(train_data, x='genre')   # график для подсчета категориальных признаков\n",
    "plt.xticks(rotation=60)\n",
    "plt.title('Distribution of movies by genre', fontsize=16);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, целевая переменная очень несбалансирована, при построении простых моделей не следует ожидать высокой точности предсказания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Очистка и подготовка описания фильма к созданию матрицы векторов.\n",
    "Подготовим наш признак, а именно описание фильма: удалим любые числа (они не отражают категорию фильма), знаки препинания, текст в скобках, приведем текст к нижнему регистру. Также преобразуем слова с помощью леммантизации к единому формату и удалим излишние стоп-слова из текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:47:26.647709Z",
     "iopub.status.busy": "2024-11-06T17:47:26.646982Z",
     "iopub.status.idle": "2024-11-06T17:48:48.665031Z",
     "shell.execute_reply": "2024-11-06T17:48:48.663984Z",
     "shell.execute_reply.started": "2024-11-06T17:47:26.647668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# функция очистки текста\n",
    "def filtered_text(df, text):\n",
    "    # удаляем любые числа, оставляя только английские слова, преобразуем к нижнему регистру\n",
    "    df['clean_text'] = df[text].apply(lambda x: re.sub(r\"[^a-z]\\w*\\d\\w*\", \" \", x.lower().strip()))\n",
    "    # удаляем любые дополнительные слова в скобках\n",
    "    df['clean_text'] = df['clean_text'].apply(lambda x: re.sub(r\"\\(.+?\\)\", \"\", x).strip())\n",
    "    # удаляем все знаки препинания\n",
    "    df['clean_text'] = df['clean_text'].str.translate(str.maketrans(\" \", \" \", string.punctuation))\n",
    "    \n",
    "    # рабиваем текст на отдельные слова-токены\n",
    "    df['clean_text'] = df['clean_text'].apply(lambda x:word_tokenize(x))\n",
    "    # леммантизация слов\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df['clean_text'] = df['clean_text'].apply(lambda x: list(map(lambda word: lemmatizer.lemmatize(word), x)))\n",
    "    # находим и удаляем стоп-слова\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df['clean_text'] = df['clean_text'].apply(lambda x: list(filter\n",
    "                                    (lambda word: word not in stop_words and len(word)>2, x)))\n",
    "    # объединяем токены обратно в текст\n",
    "    df['clean_text'] = df['clean_text'].apply(lambda x:' '.join(x))\n",
    "    return df\n",
    "\n",
    "# применим функцию к тренировочному набору \n",
    "clean_train = filtered_text(train_data, 'text')\n",
    "clean_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:48:52.722079Z",
     "iopub.status.busy": "2024-11-06T17:48:52.721692Z",
     "iopub.status.idle": "2024-11-06T17:48:52.728744Z",
     "shell.execute_reply": "2024-11-06T17:48:52.727743Z",
     "shell.execute_reply.started": "2024-11-06T17:48:52.722043Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# посмотрим на один пример очищенного текста\n",
    "clean_train.clean_text[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:48:56.073643Z",
     "iopub.status.busy": "2024-11-06T17:48:56.072795Z",
     "iopub.status.idle": "2024-11-06T17:50:15.012405Z",
     "shell.execute_reply": "2024-11-06T17:50:15.011518Z",
     "shell.execute_reply.started": "2024-11-06T17:48:56.073601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# применим функцию очистки к тестовой выборке\n",
    "clean_test = filtered_text(test_data, 'text')\n",
    "clean_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем количество уникальных слов в каждой выборке и общий размер словаря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T14:47:02.68236Z",
     "iopub.status.busy": "2024-11-06T14:47:02.681346Z",
     "iopub.status.idle": "2024-11-06T14:47:04.281964Z",
     "shell.execute_reply": "2024-11-06T14:47:04.28094Z",
     "shell.execute_reply.started": "2024-11-06T14:47:02.682306Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "words_train = [word for row in clean_train['clean_text'] for word in row.split(' ')]\n",
    "words_test = [word for row in clean_test['clean_text'] for word in row.split(' ')]\n",
    "total_voc = set(words_train+words_test)\n",
    "print('Количество слов в обучающем наборе: %s' % (len(set(words_train))),\n",
    "     'Количество слов в тестовом наборе: %s' % (len(set(words_test))),\n",
    "     'Общее количество уникальных слов: %s' % (len(total_voc)), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Создание эмбеддинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T14:48:20.167745Z",
     "iopub.status.busy": "2024-11-06T14:48:20.166977Z",
     "iopub.status.idle": "2024-11-06T14:48:35.526577Z",
     "shell.execute_reply": "2024-11-06T14:48:35.525409Z",
     "shell.execute_reply.started": "2024-11-06T14:48:20.167703Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# инициализируем векторизатор \n",
    "vectorizer = TfidfVectorizer(max_features=50000) # ограничимся четвертью из общего вокабуляра\n",
    "# преобразовываем оба набора данных в матрицу TF-IDF\n",
    "\n",
    "vectorizer.fit(pd.concat([clean_train.clean_text, clean_test.clean_text], axis=0))\n",
    "train = vectorizer.transform(clean_train.clean_text)\n",
    "test = vectorizer.transform(clean_test.clean_text)\n",
    "print('Размер выборок тренировочной и тестовой: ', train.shape, test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевую переменную закодируем порядковым номером для классификации с помощью логистической регрессии.\\\n",
    "Разделим тренировочный набор на обучающую и валидационную выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T14:52:50.023835Z",
     "iopub.status.busy": "2024-11-06T14:52:50.02345Z",
     "iopub.status.idle": "2024-11-06T14:52:50.107726Z",
     "shell.execute_reply": "2024-11-06T14:52:50.106915Z",
     "shell.execute_reply.started": "2024-11-06T14:52:50.023799Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# создаем список жанров\n",
    "genres = list(clean_train['genre'].unique())\n",
    "# создаем словарь, где каждому жанру присваиваем порядкой номер\n",
    "coding_genres = {value: num for num, value in enumerate(genres)}\n",
    "display(coding_genres)\n",
    "# применим созданный словарь к целевой переменной genre\n",
    "y = clean_train['genre'].apply(lambda x: coding_genres[x])\n",
    "\n",
    "# создадим обучающий и валидационный наборы с учетом стратификации для корректного распределения жанров по выборкам\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train, y, test_size=0.2, \n",
    "                                                      random_state=42, stratify=y)                                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Модель логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T14:53:20.986374Z",
     "iopub.status.busy": "2024-11-06T14:53:20.985547Z",
     "iopub.status.idle": "2024-11-06T14:56:12.202684Z",
     "shell.execute_reply": "2024-11-06T14:56:12.201785Z",
     "shell.execute_reply.started": "2024-11-06T14:53:20.986322Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# инициализируем алгоритм\n",
    "clf = LogisticRegression(C=20, class_weight='balanced', multi_class='multinomial',\n",
    "                         max_iter=1000, random_state=42)\n",
    "# обучаем\n",
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T14:58:26.321071Z",
     "iopub.status.busy": "2024-11-06T14:58:26.320179Z",
     "iopub.status.idle": "2024-11-06T14:58:26.363442Z",
     "shell.execute_reply": "2024-11-06T14:58:26.362553Z",
     "shell.execute_reply.started": "2024-11-06T14:58:26.32103Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# предсказываем\n",
    "y_pred = clf.predict(X_valid)\n",
    "# посмотрим значения метрик классификации на валидационной выборке\n",
    "print(classification_report(y_valid, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T14:58:38.599162Z",
     "iopub.status.busy": "2024-11-06T14:58:38.598781Z",
     "iopub.status.idle": "2024-11-06T14:58:40.69772Z",
     "shell.execute_reply": "2024-11-06T14:58:40.696735Z",
     "shell.execute_reply.started": "2024-11-06T14:58:38.599124Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# визуализируем матрицу ошибок\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "ConfusionMatrixDisplay.from_estimator(clf, X_valid, y_valid, ax=ax);\n",
    "ax.set_xticklabels(list(coding_genres.keys()), rotation=90)\n",
    "ax.set_yticklabels(list(coding_genres.keys()))\n",
    "ax.set_title('Confusion matrix of logistic regression', fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем предсказание данной моделью на тестовой выборке и сохраним полученные значения в submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T14:59:58.849488Z",
     "iopub.status.busy": "2024-11-06T14:59:58.848354Z",
     "iopub.status.idle": "2024-11-06T14:59:59.150628Z",
     "shell.execute_reply": "2024-11-06T14:59:59.149709Z",
     "shell.execute_reply.started": "2024-11-06T14:59:58.849433Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_test = clf.predict(test)\n",
    "\n",
    "# обратная функция для преобразования целевого признака из числового в категориальный строковый\n",
    "def back_genres(value):\n",
    "    return [key for key in coding_genres if coding_genres[key] == value][0]\n",
    "\n",
    "# создаем датафрейм submission с нужными колонками id и genre\n",
    "submission = pd.DataFrame(y_test, columns=['genre'])\n",
    "submission.index.name = 'id'\n",
    "submission.index += 1\n",
    "\n",
    "submission['genre'] = submission['genre'].apply(back_genres)\n",
    "print(submission)\n",
    "# сохраняем submission\n",
    "submission.to_csv('submission_logreg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простая модель средне справилась с поставленной задачей, мы попробуем также ансамблевый алгоритм - градиентный бустинг библиотеки catboost.\n",
    "\n",
    "#### 5. Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T15:02:13.065754Z",
     "iopub.status.busy": "2024-11-06T15:02:13.064796Z",
     "iopub.status.idle": "2024-11-06T15:02:13.168999Z",
     "shell.execute_reply": "2024-11-06T15:02:13.168049Z",
     "shell.execute_reply.started": "2024-11-06T15:02:13.065711Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# разделим очищенный тренировочный датасет на обучающую и валидационную выборки, \n",
    "# применяя стратификацию, помним, что целевая переменная у нас сильно несбалансирована\n",
    "Y = clean_train.genre\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(clean_train.clean_text, Y, test_size=0.2, \n",
    "                                                      random_state=42, stratify=Y) \n",
    "# проверим полученное соотношение: как целевая переменная 'genre' разделилась между выборками\n",
    "df_y_train = pd.DataFrame(data=y_train.value_counts(normalize=True).round(3)).reset_index()\n",
    "df_y_valid = pd.DataFrame(data=y_train.value_counts(normalize=True).round(3)).reset_index()\n",
    "print(pd.concat([df_y_train, df_y_valid], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T15:02:44.646163Z",
     "iopub.status.busy": "2024-11-06T15:02:44.645539Z",
     "iopub.status.idle": "2024-11-06T15:02:44.715721Z",
     "shell.execute_reply": "2024-11-06T15:02:44.714726Z",
     "shell.execute_reply.started": "2024-11-06T15:02:44.646121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# создадим обучающий и валидационнный контейнера Pool для обучения модели, чтобы повысить производительность\n",
    "train_pool = Pool(data=pd.DataFrame(clean_train['clean_text'][X_train.index]),\n",
    "                  label=pd.DataFrame(clean_train['genre'][y_train.index]), \n",
    "                  text_features=['clean_text'])\n",
    "valid_pool = Pool(data=pd.DataFrame(clean_train['clean_text'][X_valid.index]),\n",
    "                  label=pd.DataFrame(clean_train['genre'][y_valid.index]), \n",
    "                  text_features=['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T15:11:34.696809Z",
     "iopub.status.busy": "2024-11-06T15:11:34.695957Z",
     "iopub.status.idle": "2024-11-06T15:12:26.614973Z",
     "shell.execute_reply": "2024-11-06T15:12:26.61399Z",
     "shell.execute_reply.started": "2024-11-06T15:11:34.696766Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# задаем параметры модели\n",
    "catboost_params = {\n",
    "    'iterations': 1000,                 # количество итераций\n",
    "    'learning_rate': 0.04,              # шаг обучения\n",
    "    'depth': 8,                         # макс глубина одного экземпляра-дерева\n",
    "    'eval_metric': 'TotalF1',           # метрика\n",
    "    'task_type': 'GPU',               \n",
    "    'early_stopping_rounds': 50, \n",
    "    'use_best_model': True,\n",
    "    'verbose': 100,\n",
    "    'auto_class_weights': 'Balanced',\n",
    "    'random_seed': 42\n",
    "}\n",
    "# инициализируем алгоритм и передаем ему параметры\n",
    "catboost_model = CatBoostClassifier(**catboost_params)\n",
    "# обучаем\n",
    "catboost_model.fit(train_pool, eval_set=valid_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T15:12:33.816678Z",
     "iopub.status.busy": "2024-11-06T15:12:33.816324Z",
     "iopub.status.idle": "2024-11-06T15:12:34.579755Z",
     "shell.execute_reply": "2024-11-06T15:12:34.578596Z",
     "shell.execute_reply.started": "2024-11-06T15:12:33.816645Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_predicted = catboost_model.predict(valid_pool)\n",
    "print(classification_report(y_valid, y_predicted, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем предсказание на тестовой выборке и также сохраняем полученные значения в submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T15:12:54.952865Z",
     "iopub.status.busy": "2024-11-06T15:12:54.951957Z",
     "iopub.status.idle": "2024-11-06T15:12:56.130615Z",
     "shell.execute_reply": "2024-11-06T15:12:56.1297Z",
     "shell.execute_reply.started": "2024-11-06T15:12:54.952824Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_pool = Pool(data=pd.DataFrame(clean_test['clean_text']),\n",
    "                      text_features=['clean_text'])\n",
    "y_test_catboost = catboost_model.predict(test_pool)\n",
    "submission_catboost = pd.DataFrame(y_test_catboost, columns=['genre'])\n",
    "submission_catboost.index.name = 'id'\n",
    "submission_catboost.index += 1\n",
    "print(submission_catboost.head())\n",
    "submission_catboost.to_csv('submission_catboost.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, градиентный бустинг значительно уступил логистической регрессии в данной задаче."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:50:30.419016Z",
     "iopub.status.busy": "2024-11-06T17:50:30.418037Z",
     "iopub.status.idle": "2024-11-06T17:50:42.005261Z",
     "shell.execute_reply": "2024-11-06T17:50:42.004487Z",
     "shell.execute_reply.started": "2024-11-06T17:50:30.41897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# импортируем необходимые инструменты для построения простой нейронной сети\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "from keras.layers import Input, Embedding, Flatten, Dropout, MaxPooling1D\n",
    "from keras.layers import Conv1D, LSTM, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:50:44.557904Z",
     "iopub.status.busy": "2024-11-06T17:50:44.556997Z",
     "iopub.status.idle": "2024-11-06T17:50:44.581148Z",
     "shell.execute_reply": "2024-11-06T17:50:44.579975Z",
     "shell.execute_reply.started": "2024-11-06T17:50:44.557864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# закодируем one-hot-encoding целевую переменную\n",
    "Y = pd.get_dummies(train_data.genre)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:50:47.92894Z",
     "iopub.status.busy": "2024-11-06T17:50:47.928025Z",
     "iopub.status.idle": "2024-11-06T17:51:00.044394Z",
     "shell.execute_reply": "2024-11-06T17:51:00.043489Z",
     "shell.execute_reply.started": "2024-11-06T17:50:47.928897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_features = 100000                     # задаем размер словаря\n",
    "sequence_length = 100\n",
    "embedding_size = 32\n",
    "\n",
    "# создаем токенайзер\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=max_features,\n",
    "    # filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    # lower=True,\n",
    "    split=\" \",\n",
    "    char_level=False,\n",
    "    oov_token='OOV'\n",
    ")\n",
    "# используем уже подготовленный очищенный признак - описание фильма\n",
    "# обучение токенайзера делаем на всем словаре из тренировочной и тестовой выборок вместе\n",
    "tokenizer.fit_on_texts(clean_train.clean_text.to_list() + clean_test.clean_text.to_list())\n",
    "# применим токенайзер к тренировочной и тестовой выборкам\n",
    "X_train_seq = tokenizer.texts_to_sequences(clean_train.clean_text)\n",
    "X_test_seq = tokenizer.texts_to_sequences(clean_test.clean_text)\n",
    "# преобразуем созданные эммбединги (обучающий и тестовый) в последовательности одинакового размера\n",
    "X_train_pad = sequence.pad_sequences(X_train_seq, maxlen=sequence_length)  # усечение длины предложения 100\n",
    "X_test_pad = sequence.pad_sequences(X_test_seq, maxlen=sequence_length)\n",
    "print('Shape train_set: ', X_train_pad.shape, 'Shape valid_set: ', X_test_pad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим полученный тренировочный эммбединг на обучающий и валидационный, 90% отдадим на обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:51:04.477033Z",
     "iopub.status.busy": "2024-11-06T17:51:04.47631Z",
     "iopub.status.idle": "2024-11-06T17:51:06.713853Z",
     "shell.execute_reply": "2024-11-06T17:51:06.712952Z",
     "shell.execute_reply.started": "2024-11-06T17:51:04.47699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_pad, Y,\n",
    "                                                  stratify=Y,\n",
    "                                                  random_state=42,\n",
    "                                                  test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:51:10.458154Z",
     "iopub.status.busy": "2024-11-06T17:51:10.457285Z",
     "iopub.status.idle": "2024-11-06T17:51:10.465656Z",
     "shell.execute_reply": "2024-11-06T17:51:10.464646Z",
     "shell.execute_reply.started": "2024-11-06T17:51:10.458113Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# построим небольшую нейронную сеть\n",
    "def neural_model():\n",
    "    inputs = Input(shape=[sequence_length])\n",
    "    layer = Embedding(input_dim=max_features, output_dim=embedding_size, input_length=sequence_length)(inputs)\n",
    "    layer = Conv1D(filters=128, kernel_size=8, padding='same', activation='relu')(layer)\n",
    "    layer = MaxPooling1D(pool_size=4)(layer)\n",
    "    layer = LSTM(300, dropout=0.25, recurrent_dropout=0.25)(layer)  \n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(512, activation='relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(256, activation='relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(27, activation='sigmoid')(layer)\n",
    "    model = Model(inputs=inputs, outputs=layer)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:51:13.964905Z",
     "iopub.status.busy": "2024-11-06T17:51:13.964038Z",
     "iopub.status.idle": "2024-11-06T17:51:15.282827Z",
     "shell.execute_reply": "2024-11-06T17:51:15.281899Z",
     "shell.execute_reply.started": "2024-11-06T17:51:13.964861Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = neural_model()\n",
    "model.summary()\n",
    "# задаем оптимизатор, функцию потерь и метрику измерения качества\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:51:19.836925Z",
     "iopub.status.busy": "2024-11-06T17:51:19.836527Z",
     "iopub.status.idle": "2024-11-06T17:53:53.159747Z",
     "shell.execute_reply": "2024-11-06T17:53:53.158784Z",
     "shell.execute_reply.started": "2024-11-06T17:51:19.836887Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=5,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:53:59.556376Z",
     "iopub.status.busy": "2024-11-06T17:53:59.555974Z",
     "iopub.status.idle": "2024-11-06T17:53:59.897053Z",
     "shell.execute_reply": "2024-11-06T17:53:59.896085Z",
     "shell.execute_reply.started": "2024-11-06T17:53:59.556338Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# визуализируем движение метрики в процессе обучения \n",
    "plt.style.use(['dark_background'])\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('MODEL ACCURACY')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем предсказание на тестовой выборке и записываем результат в submission, сохраним его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T17:54:57.324223Z",
     "iopub.status.busy": "2024-11-06T17:54:57.323829Z",
     "iopub.status.idle": "2024-11-06T17:55:15.467094Z",
     "shell.execute_reply": "2024-11-06T17:55:15.46614Z",
     "shell.execute_reply.started": "2024-11-06T17:54:57.324186Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%time\n",
    "predictions = Y.columns[np.argmax(model.predict(X_test_pad), axis=1)]\n",
    "submission_nn = pd.DataFrame({'id': range(1,test_data.shape[0]+1), \n",
    "                           'genre': predictions})\n",
    "print(submission_nn.head())\n",
    "submission_nn.to_csv('submission_nn.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### По итогам трех примененных алгоритмов наиболее успешной оказалась логистическая регрессия, хотя ее качество не высокое.\n",
    "Для улучшения качества предсказания правильным будем поработать над самим признаком - описанием к фильму и добавить к нему определение семантического окраса."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 716656,
     "sourceId": 15145,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
